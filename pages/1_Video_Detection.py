import tempfile

import streamlit as st


# ===================== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ======================

st.set_page_config(
    layout='wide',
    initial_sidebar_state='auto',
    page_title='Face Emotion Recognition',
    page_icon='üëª',
    )

st.write("#### –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü, —ç–º–æ—Ü–∏–π, –ø–æ–ª–∞, —Ä–∞—Å—ã –∏ –≤–æ–∑—Ä–∞—Å—Ç–∞ –Ω–∞ –≤–∏–¥–µ–æ")

# –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–∏–¥–µ–æ —Å –ø—Ä–∏–º–µ—Ä–æ–º –¥–µ—Ç–µ–∫—Ü–∏–∏
@st.cache_data 
def load_main_video(video_path: str) -> bytes:
    with open(video_path, 'rb') as file:
        video_bytes = file.read()
    return video_bytes

MAIN_VIDEO_PATH = 'media/result_video.mp4'
example_video_bytes = load_main_video(MAIN_VIDEO_PATH)

video_width = 60
video_side = 100

_, container, _ = st.columns([video_side, video_width, video_side])
container.video(data=example_video_bytes)

# ===================== –ë–æ–∫–æ–≤–æ–µ –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ ======================

st.sidebar.header('–ù–∞—Å—Ç—Ä–æ–π–∫–∏')
st.sidebar.write('---')

face_conf_threshold = st.sidebar.slider(
    label='–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü',
    min_value=0.0,
    max_value=1.0,
    value=0.7,
    step=0.01,
    )
st.sidebar.write('---')

# –∫–∞–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω—É–∂–Ω–æ –¥–µ—Ç–µ–∫—Ç–∏—Ç—å (–ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ)
actions = ['age', 'gender', 'race', 'emotion']
# –ø—Ä–∏–º–µ–Ω—è—Ç—å –ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ
st.sidebar.write('–ü—Ä–∏–º–µ–Ω—è—Ç—å –ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ')
align = st.sidebar.checkbox(label='Align', value=False)


# –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
with st.spinner('–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è/–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...'):
    from detector import detector_model

# ==================== –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è =================

st_video = st.file_uploader(label='–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ')
st.session_state['video_ready_to_convert'] = False
st.session_state['annotations_ready'] = False

if st_video:
    if st.button('–î–µ—Ç–µ–∫—Ü–∏—è –≤–∏–¥–µ–æ'):
        progress_text = '–î–µ—Ç–µ–∫—Ü–∏—è –≤–∏–¥–µ–æ...'
        progress_bar = st.progress(0, text=progress_text)

        temp_file = tempfile.NamedTemporaryFile(delete=False)
        temp_file.write(st_video.read())
        video_file = temp_file.name

        generator = detector_model.detect_video(
            video_file=video_file,
            actions=actions,
            align=align,
            face_conf_threshold=face_conf_threshold,
            )
        frame_count, total_frames = next(generator)
        for (frame_count, _) in generator:
            progress_text = f'–î–µ—Ç–µ–∫—Ü–∏—è –≤–∏–¥–µ–æ, –∫–∞–¥—Ä {frame_count}/{total_frames}'
            progress_bar.progress(frame_count / total_frames, text=progress_text)
        
        progress_bar.empty()
        st.session_state['video_ready_to_convert'] = True
        detector_model.detections_to_df()

# ======= –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∏–¥–µ–æ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –±—Ä–∞—É–∑–µ—Ä–µ =================

if st.session_state['video_ready_to_convert']:
    convert_video_path = 'result_video_convert.mp4'
    with st.spinner('–ò–¥–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∏–¥–µ–æ ...'):
        detector_model.convert_mp4(detector_model.save_video_path, convert_video_path)
    # st.video(convert_video_path, format='video/mp4')

    with open(str(convert_video_path), 'rb') as file:
        video_bytes = file.read()

    _, container, _ = st.columns([video_side, video_width, video_side])
    container.video(data=video_bytes)
    
    # ======================= –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ ===================

    st.download_button(
        label='–°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ', 
        data=video_bytes, 
        file_name=detector_model.save_video_path,
        )
    st.session_state['video_ready_to_convert'] = False

